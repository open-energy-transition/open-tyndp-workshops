{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1bee99052b4b9a7",
   "metadata": {},
   "source": [
    "# Workshop 2: Introduction to `Snakemake`, new features update & benchmarking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6b79e8",
   "metadata": {},
   "source": [
    ":::{note}\n",
    "If you have not yet set up Python on your computer, you can execute this tutorial in your browser via [Google Colab](https://colab.research.google.com/). Click on the rocket in the top right corner and launch \"Colab\". If that doesn't work download the `.ipynb` file and import it in [Google Colab](https://colab.research.google.com/).\n",
    "\n",
    "Then install the following packages by executing the following command in a Jupyter cell at the top of the notebook.\n",
    "\n",
    "```sh\n",
    "!pip install pypsa pandas geopandas xarray matplotlib seaborn cartopy snakemake graphviz snakemake-storage-plugin-http\n",
    "```\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "id": "fbfeb9b020fb0a90",
   "metadata": {},
   "source": [
    "# uncomment for running this notebook on Colab\n",
    "# !pip install pypsa pandas geopandas xarray matplotlib seaborn cartopy snakemake graphviz snakemake-storage-plugin-http"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bdb98d61fbdec876",
   "metadata": {},
   "source": [
    "# import packages\n",
    "from IPython.display import Code, SVG, Image, display\n",
    "from urllib.request import urlretrieve\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "import cartopy.crs as ccrs\n",
    "import os\n",
    "import numpy as np\n",
    "import pypsa\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pypsa.plot.maps.static import (\n",
    "    add_legend_circles,\n",
    "    add_legend_patches,\n",
    "    add_legend_lines,\n",
    ")\n",
    "\n",
    "pypsa.options.params.statistics.round = 3\n",
    "pypsa.options.params.statistics.drop_zero = True\n",
    "pypsa.options.params.statistics.nice_names = False"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "736aaf6b359986fe",
   "metadata": {},
   "source": [
    "urls = {\n",
    "    \"data/data_raw.csv\": \"https://storage.googleapis.com/open-tyndp-data-store/workshop-02/data_raw.csv\",\n",
    "    \"data/open-tyndp.zip\": \"https://storage.googleapis.com/open-tyndp-data-store/workshop-02/open-tyndp.zip\",\n",
    "    \"data/network_NT_presolve_highres_2030.nc\": \"https://storage.googleapis.com/open-tyndp-data-store/workshop-02/network_NT_presolve_highres_2030.nc\",\n",
    "}\n",
    "\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "for name, url in urls.items():\n",
    "    if os.path.exists(name):\n",
    "        print(f\"File {name} already exists. Skipping download.\")\n",
    "    else:\n",
    "        print(f\"Retrieving {name} from GCP storage.\")\n",
    "        urlretrieve(url, name)\n",
    "        print(f\"File available in {name}.\")\n",
    "\n",
    "to_dir = \"data/open-tyndp\"\n",
    "if not os.path.exists(to_dir):\n",
    "    print(f\"Unzipping data/open-tyndp.zip.\")\n",
    "    ! unzip -o data/open-tyndp.zip -d data/open-tyndp\n",
    "print(f\"Open-TYNDP available in '{to_dir}'.\")\n",
    "\n",
    "print(\"Done\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f68125e0502973f",
   "metadata": {},
   "source": [
    "# The `Snakemake` tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44c6959896526ad",
   "metadata": {},
   "source": [
    "![](snakemake_logo.png)\n",
    "\n",
    "The `Snakemake` workflow management system is a tool to create reproducible and scalable data analyses.\n",
    "Workflows are described via a human readable, Python based language. They can be seamlessly scaled to server, cluster, grid, and cloud environments, without the need to modify the workflow definition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f61ff44",
   "metadata": {},
   "source": [
    "Snakemake follows the [GNU Make](https://www.gnu.org/software/make) paradigm: workflows are defined in terms of so-called `rules` that define how to create a set of output files from a set of input files. Dependencies between the rules are determined automatically, creating a DAG (directed acyclic graph) of jobs that can be automatically parallelized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c5c5e23a63e560",
   "metadata": {},
   "source": [
    ":::{note}\n",
    "Documentation for this package is available at https://snakemake.readthedocs.io/. You can also check out a [slide deck Snakemake Tutorial](https://slides.com/johanneskoester/snakemake-tutorial) by Johannes Köster (2024).\n",
    "\n",
    "Mölder, F., Jablonski, K.P., Letcher, B., Hall, M.B., Tomkins-Tinch, C.H., Sochat, V., Forster, J., Lee, S., Twardziok, S.O., Kanitz, A., Wilm, A., Holtgrewe, M., Rahmann, S., Nahnsen, S., Köster, J., 2021. Sustainable data analysis with Snakemake. F1000Res 10, 33.\n",
    ":::\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e82c9e22d6b8ce6",
   "metadata": {},
   "source": [
    "## A minimal Snakemake example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f936ab",
   "metadata": {},
   "source": [
    "To check out how this looks in practice, we've prepared a minimal Snakemake example workflow that processes some data. The minimal workflow consists of the following rules:\n",
    "- `retrieve_data`\n",
    "- `build_data`\n",
    "- `prepare_network`\n",
    "- `solve_network`\n",
    "- `plot_benchmark`\n",
    "- `all`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c33282d",
   "metadata": {},
   "source": [
    "<center>\n",
    "\n",
    "![](minimal_workflow.png)\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534d9440",
   "metadata": {},
   "source": [
    "We will first need to load the raw data file used in this minimal example into our working directory:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458220db",
   "metadata": {},
   "source": [
    "### The `Snakefile` and `rules`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ef510f",
   "metadata": {},
   "source": [
    "The rules need to be defined in a so-called `Snakefile` that sits in your current working directory. For our minimal example the `Snakefile` looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "id": "c9dfe4ae",
   "metadata": {},
   "source": [
    "Code(filename=\"Snakefile\", language=\"Python\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "677e4c85",
   "metadata": {},
   "source": [
    "### Calling a workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7ebade",
   "metadata": {},
   "source": [
    "You can then execute the workflow by specifying the target file `data/benchmark.pdf` or any intermediate file:\n",
    "```\n",
    "snakemake -call data/benchmark.pdf\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9edee26",
   "metadata": {},
   "source": [
    "Alternatively you can also execute the workflow by calling a rule that produces an intermediate file:\n",
    "```\n",
    "snakemake -call build_data\n",
    "```\n",
    "**NOTE:** You cannot call a rule that includes a wildcard without specifying what the wildcard should be filled with. Otherwise Snakemake will not know what to propagate back."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6235bc82",
   "metadata": {},
   "source": [
    "Or you can call the common rule `all` which can be used to execute the entire workflow. It takes the final workflow output as its input and thus requires all previous dependent rules to be run as well:\n",
    "```\n",
    "snakemake -call all\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fd843e",
   "metadata": {},
   "source": [
    "A very important instrument is the `-n` flag which executes a `dry-run`. It is recommended to always first execute a `dry-run` before the actual execution of the workflow. This simply prints out the directed acyclic graph (DAG) of the workflow to investigate without actually executing it.\n",
    "\n",
    "Let's try this out and investigate the output:"
   ]
  },
  {
   "cell_type": "code",
   "id": "ec82288e",
   "metadata": {},
   "source": [
    "! snakemake -call all -n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "dd6ef812",
   "metadata": {},
   "source": [
    "### Visualizing the `DAG` of a workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff53df2",
   "metadata": {},
   "source": [
    "You can also visualize the Directed Acyclic Graph of jobs, called `DAG`, using the `--dag` flag and the Graphviz `dot` command. This will not run the workflow but only create the visualization:"
   ]
  },
  {
   "cell_type": "code",
   "id": "e051153b",
   "metadata": {},
   "source": [
    "! snakemake -call all --dag | sed -n \"/digraph/,\\$p\" | dot -Tpng > dag_minimal.png"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1a4af4831b0ac3b4",
   "metadata": {},
   "source": [
    "display(Image(\"dag_minimal.png\"))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "29dd60fa",
   "metadata": {},
   "source": [
    "Rules that need to be executed will be presented as plain lines, while those that have already been executed will be presented as dotted lines. A first alternative to the DAG is the `rulegraph`. This graph is typically less crowded as you will only visualize the dependency graph of rules. This representation is leaner than the dag because rules are not repeated for wildcards."
   ]
  },
  {
   "cell_type": "code",
   "id": "d54d6fa0",
   "metadata": {},
   "source": [
    "! snakemake -call all --rulegraph | sed -n \"/digraph/,\\$p\" | dot -Tpng > rulegraph_minimal.png"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "253e9c2d",
   "metadata": {},
   "source": [
    "display(Image(\"rulegraph_minimal.png\"))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "99494ce7",
   "metadata": {},
   "source": [
    "Alternatively, you can also visualize a `filegraph` like the figure above which also includes some information about the inputs and outputs to each of the rules."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d70368",
   "metadata": {},
   "source": [
    "You can reproduce the figure from above with the following command:"
   ]
  },
  {
   "cell_type": "code",
   "id": "c1ec22d6",
   "metadata": {},
   "source": [
    "! snakemake -call all --filegraph | sed -n \"/digraph/,\\$p\" | dot -Tsvg > filegraph_minimal.svg"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "72c99998a2f27173",
   "metadata": {},
   "source": [
    "display(SVG(\"filegraph_minimal.svg\"))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cc74c230",
   "metadata": {},
   "source": [
    "## Task 1: Executing a workflow with Snakemake\n",
    "\n",
    "a) For our minimal example, execute a `dry-run` to produce the intermediate file `data/base_2030.nc`.\n",
    "\n",
    "b) Execute the workflow and investigate what happens if you try to execute the workflow again.\n",
    "\n",
    "c) Delete the final output files `data/benchmark.pdf` and investigate what happens if you try to execute the workflow again.\n",
    "\n",
    "d) Import the raw input data file `data/data_raw.csv` using pandas and save it again overwriting the original file. Investigate what happens if you try to execute the workflow again. <br>\n",
    "Hint: Alternatively you can also just `touch` the file by executing `from pathlib import Path` and `Path(\"data/data_raw.csv\").touch()`\n",
    "\n",
    "e) Finally, open the `Snakefile` and add a second rule that processes the file `data_raw_2.csv` using the same script as the `build_data` rule. Add the output of this new rule as a second input to the `prepare_network` rule."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fc1a64ecb68ac3",
   "metadata": {},
   "source": [
    "## Discover Open-TYNDP file structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759df1ccb8f8f179",
   "metadata": {},
   "source": [
    "We have already retrieved a prebuilt version of the `open-tyndp` GitHub repository into our working directory. This folder contains a run of Open-TYNDP for NT and DE scenarios, with 2030 and 2040 as planning horizons. We remove the atlite cutout from the archive and compressed the archive using `zip -r open-tyndp.zip .`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b5b10c",
   "metadata": {},
   "source": [
    "The `open-tyndp` repository contains the following structure. Directories of particular interest are marked in bold:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea24d976",
   "metadata": {},
   "source": [
    "- **benchmarks**: will store snakemake benchmarks (does not exist initially)\n",
    "- **config**: configurations used in the study\n",
    "- cutouts: will store raw weather data cutouts from atlite (does not exist initially)\n",
    "- **data**: includes input data that is not produced by any snakemake rule. Various different input files are retrieved from external storage and stored in this directory\n",
    "- doc: includes all files necessary to build the readthedocs documentation of PyPSA-Eur\n",
    "- **envs**: includes all the mamba environment specifications to run the workflow\n",
    "- logs: will store log files (does not exist initially)\n",
    "- **notebooks**: includes all the notebooks used for ad-hoc analysis\n",
    "- report: contains all files necessary to build the report; plots and result files are generated automatically\n",
    "- **rules**: includes all the snakemake rules loaded in the Snakefile\n",
    "- **resources**: will store intermediate results of the workflow which can be picked up again by subsequent rules (does not exist initially)\n",
    "- **results**: will store the solved PyPSA network data, summary files and output plots (does not exist initially)\n",
    "- **scripts**: includes all the Python scripts executed by the snakemake rules to build the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bc2c6b",
   "metadata": {},
   "source": [
    "## Task 2: Explore the folder\n",
    "\n",
    "a) Can you find the TYNDP specific data input files?\n",
    "\n",
    "b) Where can you verify the scenario and planning horizons used to produce the current results?\n",
    "\n",
    "(hint: search for `config.tyndp.yaml`)\n",
    "\n",
    "c) Can you find the hydrogen grid map in the outputs files for the NT scenario in 2040?\n",
    "\n",
    "(hint: search for `base_s_all__-h2_network_2040.pdf`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a59104",
   "metadata": {},
   "source": [
    "## Using Snakemake to launch the open-TYNDP workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29b1200c02ce786",
   "metadata": {},
   "source": [
    "We now need to change our working directory to this new directory:"
   ]
  },
  {
   "cell_type": "code",
   "id": "f190d685184837b4",
   "metadata": {},
   "source": [
    "os.chdir(\"data/open-tyndp\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "50e39aa4",
   "metadata": {},
   "source": [
    "Let's check that we are indeed in the new directory now:"
   ]
  },
  {
   "cell_type": "code",
   "id": "4db99e626b8b0309",
   "metadata": {},
   "source": [
    "os.getcwd()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ac7e3e50",
   "metadata": {},
   "source": [
    "We can now use Snakemake to call some of the rules to produce outputs with the `open-tyndp` PyPSA model. \n",
    "\n",
    "We will use the prepared TYNDP configuration file (`config/config.tyndp.yaml`) and schedule a dry-run with `-n` as we only want to investigate the DAG of the workflow:"
   ]
  },
  {
   "cell_type": "code",
   "id": "a547c6f4a2d82607",
   "metadata": {},
   "source": [
    "! snakemake -call -n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "561132a0",
   "metadata": {},
   "source": [
    "As you can see, there is nothing to be done. However, we can style explore the set of rules defined in the `Snakefile` and the other `.smk` files. First, we can plot the rule graph, then the full dag."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9208a03",
   "metadata": {},
   "source": [
    "The corresponding rule graph to this workflow will look like this:"
   ]
  },
  {
   "cell_type": "code",
   "id": "33f4913b",
   "metadata": {},
   "source": [
    "! snakemake -call --rulegraph | sed -n \"/digraph/,\\$p\" | dot -Tpng > rulegraph_open_tyndp.png"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4749ee23",
   "metadata": {},
   "source": [
    "display(Image(\"rulegraph_open_tyndp.png\"))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3685f3bc",
   "metadata": {},
   "source": [
    "The corresponding DAG to this workflow will look like this:"
   ]
  },
  {
   "cell_type": "code",
   "id": "fff1f73b",
   "metadata": {},
   "source": [
    "! snakemake -call --dag | sed -n \"/digraph/,\\$p\" | dot -Tpng > dag_open_tyndp.png"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9fac6ea7",
   "metadata": {},
   "source": [
    "display(Image(\"dag_open_tyndp.png\"))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d009cc9b",
   "metadata": {},
   "source": [
    "As you can see, this workflow is much more complicated than our minimal example from the beginning. Since we already executed the entire workflow for this demonstration, all the rules are presented as dotted lines.\n",
    "\n",
    "Nevertheless, the general idea remains the same. We retrieve data which we consequently process, then we prepare the model network and we solve it before we postprocess the results (summary, plotting, benchmarks)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4aaf85",
   "metadata": {},
   "source": [
    ":::{note}\n",
    "If you are executing this notebook on your local machine, you can also use the `conda` package manager to install the `open-tyndp` environment and run the workflow instead of dry-runs:\n",
    "```\n",
    "conda env create --file envs/<YourSystemOS>-pinned.yaml\n",
    "```\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0bcb21af782ebd",
   "metadata": {},
   "source": [
    "## Adjusting the Open-TYNDP workflow with the configuration file\n",
    "\n",
    "Let's simulate that the end of an optimisation with as last step the writing of the network file."
   ]
  },
  {
   "cell_type": "code",
   "id": "451d4d95",
   "metadata": {},
   "source": [
    "! touch results/tyndp/NT/networks/base_s_all___2040.nc"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "67377971",
   "metadata": {},
   "source": [
    "We can now see that Snakemake triggers all the rules after depends on the solved network. In this case, this is essentially plotting rules."
   ]
  },
  {
   "cell_type": "code",
   "id": "d7930fb0",
   "metadata": {},
   "source": [
    "! snakemake -call -n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "240f5e7d",
   "metadata": {},
   "source": [
    "# Update on new features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d279af",
   "metadata": {},
   "source": [
    "For the purposes of this workshop, we will primarily focus on the National Trends (NT) scenario when applicable. Four major features were introduced since our last workshop:\n",
    "1. Addition of the electricity demand and PECD capacity factors time series,\n",
    "2. Addition of onshore wind and solar TYNDP technologies (incl. PEMMDB existing capacities and trajectories),\n",
    "3. Addition of offshore hubs (incl. the offshore topology, all associated technologies, potential constraints and trajectories),\n",
    "4. Addition of hydrogen import corridors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97193552",
   "metadata": {},
   "source": [
    "# Time Series"
   ]
  },
  {
   "cell_type": "code",
   "id": "25b8565e",
   "metadata": {},
   "source": [
    "# look for renewables components\n",
    "# Explain / remind difference between time varying and fixed attributes, how to access them\n",
    "# Plot both time of parameters"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b60f0668",
   "metadata": {},
   "source": [
    "The Open-TYNDP data we retrieved contains a network with low time resolution. This is illustrative; however, since we are focusing on time series, we will use another higher resolution network. So, we will import a high resolution pre-solved network for the National Trends (NT) scenario for 2030."
   ]
  },
  {
   "cell_type": "code",
   "id": "f2079eb8",
   "metadata": {},
   "source": [
    "# hourly networks\n",
    "n_NT_2030h = pypsa.Network(\"../network_NT_presolve_highres_2030.nc\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3333d214",
   "metadata": {},
   "source": [
    "## Electricity demand"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b52e94",
   "metadata": {},
   "source": [
    "We can then explore the electricity demand that is attached to the network. Can you remember how to access `Loads` time series in PyPSA?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46775be5",
   "metadata": {},
   "source": [
    "Correct! You can use the `loads_t` key and its `p_set` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "id": "95d3ae39",
   "metadata": {},
   "source": [
    "loads_2030 = n_NT_2030h.loads_t.p_set\n",
    "loads_2030.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "05458163",
   "metadata": {},
   "source": [
    "Let's plot the electricity demand time series:"
   ]
  },
  {
   "cell_type": "code",
   "id": "85992bcd",
   "metadata": {},
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "loads_2030.div(1e3).plot(\n",
    "    xlabel=\"Time\",\n",
    "    ylabel=\"Load [GW]\",\n",
    "    title=\"Electricity Load Time Series - NT - 2030\",\n",
    "    grid=True,\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "ax.legend(loc=\"upper center\", bbox_to_anchor=(0.5, -0.15), ncols=10)\n",
    "ax.grid(True, linestyle=\"--\");"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5cdd854e",
   "metadata": {},
   "source": [
    "This is very confusing to look at. Let's filter that down a bit..."
   ]
  },
  {
   "cell_type": "code",
   "id": "31bfe14f",
   "metadata": {},
   "source": [
    "# group country profiles together and select a week\n",
    "country_mapping = n_NT_2030h.buses.query(\"carrier=='AC'\").country\n",
    "loads_2030_by_country = (\n",
    "    n_NT_2030h.loads_t.p_set.T.rename(country_mapping, axis=0)\n",
    "    .groupby(\"Load\")\n",
    "    .sum()\n",
    "    .T.loc[\"2009-03-01\":\"2009-03-07\", [\"FR\", \"DE\", \"GB\"]]\n",
    ")\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "loads_2030_by_country.div(1e3).plot(\n",
    "    xlabel=\"Time\",\n",
    "    ylabel=\"Load [GW]\",\n",
    "    title=\"Electricity Load Time Series - NT - 2030\",\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "ax.grid(True, linestyle=\"--\")\n",
    "ax.legend();"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "90e32485",
   "metadata": {},
   "source": [
    "## Task 3: Use PyPSA statistics to explore the load\n",
    "\n",
    "Can you remember how to use the **PyPSA Statistics** module that we introduced in the last workshop to interactively visualize these electricity demand inputs from the network:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7672932",
   "metadata": {},
   "source": [
    "First, we need to load a lower-resolution network that was solved, so we can use the statistics module to analyze it."
   ]
  },
  {
   "cell_type": "code",
   "id": "7181673d",
   "metadata": {},
   "source": [
    "n_NT_2030 = pypsa.Network(\"results/tyndp/NT/networks/base_s_all___2030.nc\")\n",
    "n_NT_2030.carriers.loc[\"none\", \"color\"] = \"#000000\"\n",
    "n_NT_2030.carriers.loc[\"\", \"color\"] = \"#000000\"\n",
    "\n",
    "n_DE_2040 = pypsa.Network(\"results/tyndp/DE/networks/base_s_all___2040.nc\")\n",
    "n_DE_2040.carriers.loc[\"none\", \"color\"] = \"#000000\"\n",
    "n_DE_2040.carriers.loc[\"\", \"color\"] = \"#000000\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "02b9c885",
   "metadata": {},
   "source": [
    "# let's define a helper variable\n",
    "s = n_NT_2030.statistics"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1e1d1658",
   "metadata": {},
   "source": [
    "Let's access the data using `s.withdrawal()`."
   ]
  },
  {
   "cell_type": "code",
   "id": "4952e155",
   "metadata": {},
   "source": [
    "s.withdrawal(\n",
    "    bus_carrier=\"low voltage\", comps=\"Load\", aggregate_time=False, groupby=False\n",
    ").T.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "41247bcd",
   "metadata": {},
   "source": [
    "We can also plot all the countries at the same time..."
   ]
  },
  {
   "cell_type": "code",
   "id": "957d953b",
   "metadata": {},
   "source": [
    "fig, ax, facet_grid = s.withdrawal.plot.line(\n",
    "    bus_carrier=\"low voltage\",\n",
    "    y=\"value\",\n",
    "    x=\"snapshot\",\n",
    "    color=\"country\",\n",
    ")\n",
    "fig.suptitle(\"Electricity demand Time Series - NT - 2030\", y=1.05)\n",
    "ax.set_ylabel(\"Load [MW]\")\n",
    "ax.set_xlabel(\"Time\");"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d1d173ee",
   "metadata": {},
   "source": [
    "This is once again difficult to read. Let's keep only two countries."
   ]
  },
  {
   "cell_type": "code",
   "id": "f9a4a6c0",
   "metadata": {},
   "source": [
    "fig, ax, facet_col = s.withdrawal.plot.area(\n",
    "    bus_carrier=\"low voltage\",\n",
    "    y=\"value\",\n",
    "    x=\"snapshot\",\n",
    "    color=\"carrier\",\n",
    "    stacked=True,\n",
    "    facet_row=\"country\",\n",
    "    query=\"carrier == 'electricity' and country in ['DE', 'FR']\",\n",
    ")\n",
    "fig.suptitle(\"Electricity demand Time Series - NT - 2030\", y=1.05)\n",
    "ax[0, 0].set_ylabel(\"Load [MW]\")\n",
    "ax[1, 0].set_ylabel(\"Load [MW]\")\n",
    "ax[1, 0].set_xlabel(\"Time\");"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b93a51e6",
   "metadata": {},
   "source": [
    "## PECD capacity factors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acd585d",
   "metadata": {},
   "source": [
    "The Pan-European Climate Database (PECD) provides capacity factor profiles for all the different renewable technologies used in the TYNDP. We processed these input data files into a Python and PyPSA friendly input format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea2437f",
   "metadata": {},
   "source": [
    "Let's start by looking at the processed capacity factor time series for solar PV Utility for 2030. These processed data are stored in the `resources` directory, as they are an output of `build_renewable_profiles_pecd`. We will filter the data to a set of countries and a week."
   ]
  },
  {
   "cell_type": "code",
   "id": "db551850",
   "metadata": {},
   "source": [
    "cf_pv_rftp = pd.read_csv(\n",
    "    \"resources/tyndp/NT/pecd_data_LFSolarPVRooftop_2030.csv\",\n",
    "    index_col=0,\n",
    "    parse_dates=True,\n",
    ").loc[\"2009-07-01\":\"2009-07-04\", [\"SE04\", \"DE00\", \"FR00\", \"ES00\"]]\n",
    "cf_pv_rftp.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "0c853fb2",
   "metadata": {},
   "source": [
    "Using a heatmap, we can better grasp the content of the data."
   ]
  },
  {
   "cell_type": "code",
   "id": "f0947d0e",
   "metadata": {},
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "sns.heatmap(cf_pv_rftp.T, cmap=\"viridis\", cbar_kws={\"label\": \"Capacity Factor\"}, ax=ax)\n",
    "\n",
    "tick_positions = range(0, len(cf_pv_rftp), 24)\n",
    "ax.set_xticks(tick_positions)\n",
    "ax.set_xticklabels(\n",
    "    cf_pv_rftp.index[tick_positions].strftime(\"%Y-%m-%d\"), rotation=45, ha=\"right\"\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"Time\")\n",
    "ax.set_ylabel(\"Node\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f73476ae",
   "metadata": {},
   "source": [
    "We can also present the data as time series."
   ]
  },
  {
   "cell_type": "code",
   "id": "6c4c327b",
   "metadata": {},
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "\n",
    "cf_pv_rftp.plot(\n",
    "    title=\"Capacity Factor Time Series National Trends 2030 - March 1-4\",\n",
    "    xlabel=\"Date\",\n",
    "    ylabel=\"Capacity Factor\",\n",
    "    ax=ax,\n",
    ");"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7785fc1f",
   "metadata": {},
   "source": [
    "## Task 4: Compute average capacity factor\n",
    "\n",
    "a) Locate the resource file with onwind capacity factors used for NT in 2030.\n",
    "\n",
    "b) Compute the average onwind capacity factor for all the countries in the PECD.\n",
    "\n",
    "c) Verify one of the values directly in the network.\n",
    "\n",
    "(hint: capacity factors are defined as time varying parameter of generators and are called `p_max_pu`)"
   ]
  },
  {
   "cell_type": "code",
   "id": "b3a9d8c3",
   "metadata": {},
   "source": [
    "cf_onwind = pd.read_csv(\n",
    "    \"resources/tyndp/NT/pecd_data_Wind_Onshore_2030.csv\",\n",
    "    index_col=0,\n",
    "    parse_dates=True,\n",
    ")\n",
    "cf_onwind.head();"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "56a498d8",
   "metadata": {},
   "source": [
    "cf_onwind.columns = cf_onwind.columns.str[:2]\n",
    "cf_onwind.columns.name = \"country\"\n",
    "cf_onwind.head();"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b9b3880b",
   "metadata": {},
   "source": [
    "cf_onwind_sorted = cf_onwind.T.groupby(by=\"country\").mean().mean(axis=1).sort_values()\n",
    "cf_onwind_sorted.tail();"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a38a78cb",
   "metadata": {},
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 9))\n",
    "cf_onwind_sorted.plot.barh(\n",
    "    title=\"Average capacity factors - 2030\",\n",
    "    xlabel=\"Capacity factor [p.u]\",\n",
    "    ylabel=\"Country\",\n",
    "    ax=ax,\n",
    ");"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fd1e4d6a",
   "metadata": {},
   "source": [
    "c_buses = n_NT_2030h.buses.query(\"country=='IE'\").index\n",
    "c_gen = n_NT_2030h.generators.query(\"carrier=='onwind' and bus in @c_buses\").index\n",
    "c_cf = n_NT_2030h.generators_t.p_max_pu[c_gen]\n",
    "c_cf.mean()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "aad8ea68",
   "metadata": {},
   "source": [
    "# Onshore wind and solar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff4066e",
   "metadata": {},
   "source": [
    "The TYNDP provides expansion trajectories for given investment candidates and expandable technologies. For the implemented onshore wind and solar technologies, these have been included in beta release v0.3 of the Open-TYNDP model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4d750f",
   "metadata": {},
   "source": [
    "It is possible to retrieve those values from the network. However, for simplicity, we will import the values directly from the processed input files for the `DE` scenario to investigate the entire trajectory paths at once."
   ]
  },
  {
   "cell_type": "code",
   "id": "a651700d",
   "metadata": {},
   "source": [
    "trajectories = pd.read_csv(\"resources/tyndp/DE/tyndp_trajectories.csv\")\n",
    "trajectories.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "28cbceb0",
   "metadata": {},
   "source": [
    "Similar to the capacity factor time series, we want to focus on the Solar PV Rooftop technology and its trajectory path. Let's take Germany (DE00) to investigate."
   ]
  },
  {
   "cell_type": "code",
   "id": "19b984f5",
   "metadata": {},
   "source": [
    "trajectories_pv_utility_de = (\n",
    "    trajectories.query(\"carrier == 'solar-pv-rooftop' and bus == 'DE00'\")\n",
    "    .sort_values(by=\"pyear\")\n",
    "    .set_index(\"pyear\")[[\"p_nom_min\", \"p_nom_max\"]]\n",
    "    .div(1e3)  # GW\n",
    ")\n",
    "trajectories_pv_utility_de"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4f8e1844",
   "metadata": {},
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "trajectories_pv_utility_de.plot(\n",
    "    title=\"Solar PV Utility Capacity Trajectories - DE scenario - DE00\",\n",
    "    xlabel=\"Planning Year\",\n",
    "    ylabel=\"Capacity [GW]\",\n",
    "    color=[\"#E63946\", \"#1D3557\"],\n",
    "    style=\"*--\",\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "ax.fill_between(\n",
    "    trajectories_pv_utility_de.index,\n",
    "    trajectories_pv_utility_de.iloc[:, 0],\n",
    "    trajectories_pv_utility_de.iloc[:, 1],\n",
    "    alpha=0.25,\n",
    "    color=\"#457B9D\",\n",
    "    label=\"Trajectory Range\",\n",
    ")\n",
    "\n",
    "ax.xaxis.set_major_locator(MultipleLocator(5))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8d957d3c",
   "metadata": {},
   "source": [
    "Now, let's access the network for the DE scenario to compare one of these trajectory values for 2040."
   ]
  },
  {
   "cell_type": "code",
   "id": "567331da",
   "metadata": {},
   "source": [
    "trajectories_pv_utility_de_from_network = n_DE_2040.generators.query(\n",
    "    \"carrier == 'solar-pv-utility' and bus == 'DE00'\"\n",
    ")[[\"p_nom\", \"p_nom_min\", \"p_nom_max\"]].div(\n",
    "    1e3\n",
    ")  # in GW\n",
    "trajectories_pv_utility_de_from_network"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "72a3c693",
   "metadata": {},
   "source": [
    "As we can see, the `p_nom_max` and `p_nom_min` values for 2040 do not match directly with the reported trajectory values analyzed above. This is because each new Generator will have set trajectories that correspond to the new cumulatively installed capacities taking into account optimization results from previous years. Therefore, if we add up the existing capacity (`p_nom`) from 2030 to the `p_nom_max` and `p_nom_min` values from 2040, we will obtain the reported trajectory values shown above:"
   ]
  },
  {
   "cell_type": "code",
   "id": "e0899d25",
   "metadata": {},
   "source": [
    "(\n",
    "    trajectories_pv_utility_de_from_network.loc[\n",
    "        \"DE00 0 solar-pv-utility-2040\", [\"p_nom_min\", \"p_nom_max\"]\n",
    "    ]\n",
    "    + trajectories_pv_utility_de_from_network.loc[\n",
    "        \"DE00 0 solar-pv-utility-2030\", \"p_nom\"\n",
    "    ]\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "49f0d930",
   "metadata": {},
   "source": [
    "## Task 5: Verify onshore wind trajectories\n",
    "\n",
    "Verify onshore wind trajectories in the network itself. This can be quick if you can copy and reuse the existing code used above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5d366c",
   "metadata": {},
   "source": [
    "# Offshore Hubs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705131c2",
   "metadata": {},
   "source": [
    "To implement the offshore methodology, new carriers (*i.e.*, technologies) are introduced. All the offshore technologies start with `offwind`."
   ]
  },
  {
   "cell_type": "code",
   "id": "90d46b43",
   "metadata": {},
   "source": [
    "offwind_carriers = n_NT_2030.carriers.query(\"Carrier.str.contains('offwind')\")\n",
    "offwind_carriers_i = offwind_carriers.index\n",
    "offwind_carriers"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "585d7896",
   "metadata": {},
   "source": [
    "As you can see in the table above, all the offshore technologies are implemented. We model technologies that are a combination of the following:\n",
    "- both AC `ac` and DC `dc` zones, as well as H2 generating windfarms `h2`;\n",
    "- both fixed-bottom `fb` and floating `fl` foundations;\n",
    "- both radial `r` and hub `oh` connections."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf4935d",
   "metadata": {},
   "source": [
    "We also introduce new offshore buses, both for electricity and hydrogen. Electricity buses use `AC_OH` as the carrier, while hydrogen buses use `H2_OH`."
   ]
  },
  {
   "cell_type": "code",
   "id": "6c1ea60c",
   "metadata": {},
   "source": [
    "n_NT_2030.buses.query(\"carrier.str.contains('OH')\").head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "940bb32a",
   "metadata": {},
   "source": [
    "Let's narrow down this list to a single country."
   ]
  },
  {
   "cell_type": "code",
   "id": "1edd71d8",
   "metadata": {},
   "source": [
    "buses = n_NT_2030.buses.query(\"carrier.str.contains('OH') and country=='BE'\")\n",
    "buses_i = buses.index\n",
    "buses"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3d2b3577",
   "metadata": {},
   "source": [
    "Using `n.plot.explore()`, we can easily get an overview of the network topology. Let's clean the network before exploring it to only focus on the electrical offshore topology."
   ]
  },
  {
   "cell_type": "code",
   "id": "2bb486c6",
   "metadata": {},
   "source": [
    "# let's filter AC_OH buses and explore\n",
    "n_explore_ac = n_NT_2030.copy()\n",
    "n_explore_ac.remove(\"Bus\", n_explore_ac.buses.query(\"carrier not in ['AC_OH']\").index)\n",
    "n_explore_ac.plot.explore()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3e9a521b",
   "metadata": {},
   "source": [
    "Now, we can search the network for generators that are defined with those carriers."
   ]
  },
  {
   "cell_type": "code",
   "id": "07229e67",
   "metadata": {},
   "source": [
    "n_NT_2030.generators.query(\"carrier in @offwind_carriers_i\").head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "039b187e",
   "metadata": {},
   "source": [
    "Let's focus on a specific country:"
   ]
  },
  {
   "cell_type": "code",
   "id": "d2860601",
   "metadata": {},
   "source": [
    "n_NT_2030.generators.query(\"carrier in @offwind_carriers_i and bus in @buses_i\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f07ca985",
   "metadata": {},
   "source": [
    "## Task 6: Extract existing offshore capacities\n",
    "\n",
    "Extract existing offshore capacities for the country of your choice."
   ]
  },
  {
   "cell_type": "code",
   "id": "a47bb4cf",
   "metadata": {},
   "source": [
    "n_DE_2040.statistics.optimal_capacity(\n",
    "    bus_carrier=[\"AC\", \"AC_OH\", \"H2_OH\"],\n",
    "    comps=\"Generator\",\n",
    "    groupby=[\"bus\"],\n",
    ").to_frame().query(\"bus.str.contains('BE')\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2b34b371",
   "metadata": {},
   "source": [
    "fig, ax, facet_grid = n_DE_2040.statistics.optimal_capacity.plot.bar(\n",
    "    bus_carrier=[\"AC\", \"AC_OH\", \"H2_OH\"],\n",
    "    query=\"carrier.str.startswith('offwind') and country in ['NL', 'GB']\",\n",
    "    facet_col=\"country\",\n",
    ")\n",
    "fig.suptitle(\"Offshore wind capacities - DE - 2040\", y=1.05);"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2fa0d42f",
   "metadata": {},
   "source": [
    "We can also explore the data with maps."
   ]
  },
  {
   "cell_type": "code",
   "id": "7309445e",
   "metadata": {},
   "source": [
    "# Let's clean a network copy to only keep offshore data\n",
    "n_map = n_DE_2040.copy()\n",
    "n_map.remove(\"Bus\", n_map.buses.query(\"carrier not in ['AC', 'AC_OH', 'H2_OH']\").index)\n",
    "n_map.remove(\n",
    "    \"Generator\", n_map.generators.query(\"not carrier.str.startswith('offwind')\").index\n",
    ")\n",
    "n_map.remove(\"Link\", n_map.links.index)\n",
    "n_map.remove(\"StorageUnit\", n_map.storage_units.index)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "03488719",
   "metadata": {},
   "source": [
    "# Define map projection\n",
    "def load_projection(plotting_params):\n",
    "    proj_kwargs = plotting_params.get(\"projection\", dict(name=\"EqualEarth\"))\n",
    "    proj_func = getattr(ccrs, proj_kwargs.pop(\"name\"))\n",
    "    return proj_func(**proj_kwargs)\n",
    "\n",
    "\n",
    "proj = load_projection(dict(name=\"EqualEarth\"))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0d304aee",
   "metadata": {},
   "source": [
    "# Create the map\n",
    "subplot_kw = {\"projection\": proj}\n",
    "fig, ax = plt.subplots(figsize=(12, 12), subplot_kw=subplot_kw)\n",
    "n_map.statistics.optimal_capacity.plot.map(\n",
    "    bus_carrier=[\"AC\", \"AC_OH\", \"H2_OH\"],\n",
    "    ax=ax,\n",
    "    bus_area_fraction=0.002,\n",
    "    title=\"Offshore wind capacities - DE - 2040\",\n",
    ");"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d82157b9",
   "metadata": {},
   "source": [
    "The NT scenario is a dispatch scenario. This is translated in PyPSA with the argument `p_nom_extendable = False`. However, for the two other scenario, we need to model capacity expansion. \n",
    "\n",
    "Currently, the model is configured to do myopic optimisaiton. This means that only the capacities of the current planning horizon are expandable. Generators of the previous planning horizon are not. Let's check this the network."
   ]
  },
  {
   "cell_type": "code",
   "id": "f04fa77e",
   "metadata": {},
   "source": [
    "# Let's explore offshore wind generators in Danemark\n",
    "c_buses = n_DE_2040.buses.query(\"country == 'DK'\").index\n",
    "(\n",
    "    n_DE_2040.generators.query(\"carrier in @offwind_carriers_i and bus in @c_buses\")[\n",
    "        [\"p_nom\", \"p_nom_min\", \"p_nom_max\", \"p_nom_opt\", \"p_nom_extendable\"]\n",
    "    ]\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3cf4a2e0",
   "metadata": {},
   "source": [
    "As you can in the table, multiple values exists:\n",
    "- `p_nom`, the nominal power\n",
    "- `p_nom_min`, if p_nom is extendable, the minimal value\n",
    "- `p_nom_max`, if p_nom is extendable, the maximal value\n",
    "- `p_nom_opt`, the optimised nominal power\n",
    "\n",
    "The `p_nom_min` reflects the exesting capacities defined in the TYNDP, while the `p_nom_max` represent the layer potential. We also implemented constraints to ensure to respect the zone potentials and the trajectories defined in the data:\n",
    "- A constraint limits the expansion of DC and H2 sitting on the same location, as the sum of the two capacities cannot exceed the layer potential.\n",
    "- A constraint sets the maximum potential per zone, taking into account the zone trajectories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee8acb4",
   "metadata": {},
   "source": [
    "# H2 imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bac7c7f",
   "metadata": {},
   "source": [
    "There have also been some important additions to the H2 infrastructure since our last workshop. The different H2 import corridors are now included in the model with a simple pipeline transport representation, similar to the H2 reference grid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b41d4c",
   "metadata": {},
   "source": [
    "The import pipelines are implemented using PyPSA's link component. As is convention in PyPSA, this means `bus0` represents the external import node and `bus1` the importing country's Hydrogen Zone 2 node.\n",
    "\n",
    "We can investigate our National Trends network and list the importing nodes/buses."
   ]
  },
  {
   "cell_type": "code",
   "id": "9aa1281b",
   "metadata": {},
   "source": [
    "h2_import_links = n_NT_2030.links.filter(like=\"H2 import\", axis=0)\n",
    "h2_import_links.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "68fef04f",
   "metadata": {},
   "source": [
    "set(h2_import_links.bus1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4cdcdc07",
   "metadata": {},
   "source": [
    "As we can see from the `p_nom_extendable` attribute of these links, the H2 import corridors cannot be endogenously expanded by the model but are rather fixed inputs as in the TYNDP 2024 methodology."
   ]
  },
  {
   "cell_type": "code",
   "id": "4ef640ce",
   "metadata": {},
   "source": [
    "h2_import_links[[\"bus0\", \"bus1\", \"carrier\", \"p_nom_extendable\"]]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b5d95f58",
   "metadata": {},
   "source": [
    "### Task 7: Investigate H2 import corridors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140794ed",
   "metadata": {},
   "source": [
    " Extract and investigate the different import corridors for one specific country of your choice and for the year 2040 using our Distributed Energy network for 2040."
   ]
  },
  {
   "cell_type": "code",
   "id": "00af5581",
   "metadata": {},
   "source": [
    "(   \n",
    "    n_DE_2040.links.filter(like=\"H2 import\", axis=0)\n",
    "    .query(\"bus1.str.contains('BE')\")\n",
    "    [[\"bus0\", \"bus1\", \"carrier\", \"p_nom\"]]\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "63a5ac92",
   "metadata": {},
   "source": [
    "We can investigate our Distributed Energy network to create a similar plot like we created last time. Let's import some plotting functions from the open-tyndp workflow for this:"
   ]
  },
  {
   "cell_type": "code",
   "id": "ef556c1e",
   "metadata": {},
   "source": [
    "os.chdir(\"scripts\")\n",
    "from plot_base_hydrogen_network import plot_h2_map_base"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "aa3ec517",
   "metadata": {},
   "source": [
    "And plot the H2 reference grid together with the import corridors:"
   ]
  },
  {
   "cell_type": "code",
   "id": "8020a5da",
   "metadata": {},
   "source": [
    "n = n_DE_2040.copy()\n",
    "\n",
    "\n",
    "def load_projection(plotting_params):\n",
    "    proj_kwargs = plotting_params.get(\"projection\", dict(name=\"EqualEarth\"))\n",
    "    proj_func = getattr(ccrs, proj_kwargs.pop(\"name\"))\n",
    "    return proj_func(**proj_kwargs)\n",
    "\n",
    "\n",
    "proj = load_projection(dict(name=\"EqualEarth\"))\n",
    "\n",
    "map_opts = {\n",
    "    \"boundaries\": [-11, 30, 34, 71],\n",
    "    \"geomap_colors\": {\n",
    "        \"ocean\": \"white\",\n",
    "        \"land\": \"white\",\n",
    "    },\n",
    "}\n",
    "\n",
    "if n.buses.country.isin([\"MA\", \"DZ\"]).any():\n",
    "    map_opts[\"boundaries\"] = list(np.add(map_opts[\"boundaries\"], [0, 0, -6, 0]))\n",
    "\n",
    "plot_h2_map_base(\n",
    "    network=n, \n",
    "    map_opts=map_opts,\n",
    "    map_fn=\"../../../h2_import_corridors_DE2040.png\",\n",
    ")\n",
    "display(Image(\"../../../h2_import_corridors_DE2040.png\"))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "156f86cb",
   "metadata": {},
   "source": [
    "### Task 8: Plot and compare H2 imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba58296",
   "metadata": {},
   "source": [
    "Plot and compare the H2 import corridors between National Trends 2030 using our prepared network and compare with the Distributed Energy 2040 figure from above.\n",
    "\n",
    "Hint: You can reuse the plotting function from above."
   ]
  },
  {
   "cell_type": "code",
   "id": "52805137",
   "metadata": {},
   "source": [
    "n = n_NT_2030.copy()\n",
    "\n",
    "plot_h2_map_base(\n",
    "    network=n, \n",
    "    map_opts=map_opts,\n",
    "    map_fn=\"../../../h2_import_corridors_NT2030.png\",\n",
    ")\n",
    "display(Image(\"../../../h2_import_corridors_NT2030.png\"))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f16ae2fe",
   "metadata": {},
   "source": [
    "# Benchmarking framework"
   ]
  },
  {
   "cell_type": "code",
   "id": "82e62f77",
   "metadata": {},
   "source": [
    "# Present metrics used (incl. reference to methodology)\n",
    "# Data sources used for comparison\n",
    "# Mention introduction of onwind and solar\n",
    "# Showcase current status\n",
    "# --- Table\n",
    "# --- Graphs"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cc6f22d8",
   "metadata": {},
   "source": [
    "# Wrap up"
   ]
  },
  {
   "cell_type": "code",
   "id": "da40d5af",
   "metadata": {},
   "source": [
    "# Collect feedback via Slido"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open-tyndp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
