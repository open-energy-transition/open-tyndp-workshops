{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Workshop 2: Introduction to `Snakemake`, new features update & benchmarking",
   "id": "43d4d05bd9355d0d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    ":::{note} At the end of this notebook, you will be able to:\n",
    "\n",
    "- Describe key concepts of workflow tools such as Snakemake\n",
    "- Navigate the Open-TYNDP folder structure\n",
    "- Execute all or specific rules within the Open-TYNDP Snakemake workflow\n",
    "- Explain the new features added to Open-TYNDP v0.3\n",
    "- Use the benchmarking framework\n",
    "\n",
    ":::"
   ],
   "id": "491739e5cb8aa72b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    ":::{note}\n",
    "If you have not yet set up Python on your computer, you can execute this tutorial in your browser via [Google Colab](https://colab.research.google.com/). Click on the rocket in the top right corner and launch \"Colab\". If that doesn't work download the `.ipynb` file and import it in [Google Colab](https://colab.research.google.com/).\n",
    "\n",
    "Then install the following packages by executing the following command in a Jupyter cell at the top of the notebook.\n",
    "\n",
    "```sh\n",
    "!pip install \"pypsa<1.0\" pandas geopandas xarray matplotlib seaborn cartopy snakemake graphviz snakemake-storage-plugin-http pdf2image atlite fiona powerplantmatching folium mapclassify\n",
    "!apt-get install poppler-utils\n",
    "```\n",
    ":::"
   ],
   "id": "85a4110b270d7c6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# uncomment for running this notebook on Colab\n",
    "# !pip install \"pypsa<1.0\" pandas geopandas xarray matplotlib seaborn cartopy snakemake graphviz snakemake-storage-plugin-http pdf2image atlite fiona powerplantmatching folium mapclassify\n",
    "# !apt-get install poppler-utils"
   ],
   "id": "6da31b6a0dd7d1bc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T11:22:45.729645Z",
     "start_time": "2025-10-31T11:22:44.484321Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import zipfile\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pypsa\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from IPython.display import Code, SVG, Image, IFrame, display\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "from pdf2image import convert_from_path\n",
    "from pypsa.plot.maps.static import (\n",
    "    add_legend_circles,\n",
    "    add_legend_lines,\n",
    "    add_legend_patches,\n",
    ")\n",
    "\n",
    "pypsa.options.params.statistics.round = 3\n",
    "pypsa.options.params.statistics.drop_zero = True\n",
    "pypsa.options.params.statistics.nice_names = False\n",
    "plt.rcParams[\"figure.figsize\"] = [14, 7]"
   ],
   "id": "417e340f6ebbe2d3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T11:22:45.740056Z",
     "start_time": "2025-10-31T11:22:45.738006Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def unzip_with_timestamps(zip_path, extract_to):\n",
    "    \"\"\"Unzip a file while preserving original file timestamps.\"\"\"\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        for member in zip_ref.infolist():\n",
    "            # Extract the file\n",
    "            zip_ref.extract(member, extract_to)\n",
    "\n",
    "            # Get the extracted file path\n",
    "            extracted_path = os.path.join(extract_to, member.filename)\n",
    "\n",
    "            # Set the modification time from the zip file\n",
    "            date_time = datetime(*member.date_time)\n",
    "            timestamp = date_time.timestamp()\n",
    "\n",
    "            # Update both access and modification times\n",
    "            os.utime(extracted_path, (timestamp, timestamp))"
   ],
   "id": "2d53b373fd84ec9b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T11:22:46.208356Z",
     "start_time": "2025-10-31T11:22:45.743263Z"
    }
   },
   "cell_type": "code",
   "source": [
    "urls = {\n",
    "    \"data/data_raw.csv\": \"https://storage.googleapis.com/open-tyndp-data-store/workshop-02/data_raw.csv\",\n",
    "    \"data/open-tyndp.zip\": \"https://storage.googleapis.com/open-tyndp-data-store/workshop-02/open-tyndp.zip\",\n",
    "    \"data/network_NT_presolve_highres_2030.nc\": \"https://storage.googleapis.com/open-tyndp-data-store/workshop-02/network_NT_presolve_highres_2030.nc\",\n",
    "    \"Snakefile\": \"https://raw.githubusercontent.com/open-energy-transition/open-tyndp-workshops/refs/heads/main/open-tyndp-workshops/Snakefile\",\n",
    "    \"scripts/build_data.py\": \"https://raw.githubusercontent.com/open-energy-transition/open-tyndp-workshops/refs/heads/main/open-tyndp-workshops/scripts/build_data.py\",\n",
    "    \"scripts/prepare_network.py\": \"https://raw.githubusercontent.com/open-energy-transition/open-tyndp-workshops/refs/heads/main/open-tyndp-workshops/scripts/prepare_network.py\",\n",
    "}\n",
    "\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "os.makedirs(\"scripts\", exist_ok=True)\n",
    "for name, url in urls.items():\n",
    "    if os.path.exists(name):\n",
    "        print(f\"File {name} already exists. Skipping download.\")\n",
    "    else:\n",
    "        print(f\"Retrieving {name} from GCP storage.\")\n",
    "        urlretrieve(url, name)\n",
    "        print(f\"File available in {name}.\")\n",
    "\n",
    "to_dir = \"data/open-tyndp\"\n",
    "if not os.path.exists(to_dir):\n",
    "    print(f\"Unzipping data/open-tyndp.zip.\")\n",
    "    unzip_with_timestamps(\"data/open-tyndp.zip\", \"data/open-tyndp\")\n",
    "print(f\"Open-TYNDP available in '{to_dir}'.\")\n",
    "\n",
    "print(\"Done\")"
   ],
   "id": "5615e14b40a017e5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# The `Snakemake` tool",
   "id": "133b58a0f68eccfe"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "![](snakemake_logo.png)\n",
    "\n",
    "The `Snakemake` workflow management system is a tool to create reproducible and scalable data analyses.\n",
    "Workflows are described via a human readable, Python based language. They can be seamlessly scaled to server, cluster, grid, and cloud environments, without the need to modify the workflow definition."
   ],
   "id": "ad32b6db8b718279"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Snakemake follows the [GNU Make](https://www.gnu.org/software/make) paradigm: workflows are defined in terms of so-called `rules` that specify how to create a set of output files from a set of input files. Dependencies between the rules are determined automatically, creating a DAG (directed acyclic graph) of jobs that can be automatically parallelized.",
   "id": "2b2aa5dac52d0e80"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    ":::{note}\n",
    "Documentation for this package is available at https://snakemake.readthedocs.io/. You can also check out a [slide deck Snakemake Tutorial](https://slides.com/johanneskoester/snakemake-tutorial) by Johannes Köster (2024).\n",
    "\n",
    "Mölder, F., Jablonski, K.P., Letcher, B., Hall, M.B., Tomkins-Tinch, C.H., Sochat, V., Forster, J., Lee, S., Twardziok, S.O., Kanitz, A., Wilm, A., Holtgrewe, M., Rahmann, S., Nahnsen, S., Köster, J., 2021. Sustainable data analysis with Snakemake. F1000Res 10, 33.\n",
    ":::\n"
   ],
   "id": "70f07cf60407bdad"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## A minimal Snakemake example",
   "id": "1da1f78d05666a00"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "To check out how this looks in practice, we've prepared a minimal Snakemake example workflow that processes some data. The minimal workflow consists of the following rules:\n",
    "- `retrieve_data`\n",
    "- `build_data`\n",
    "- `prepare_network`\n",
    "- `solve_network`\n",
    "- `plot_benchmark`\n",
    "- `all`\n",
    "\n",
    "These rules are illustrative and mimic the Open-TYNDP structure and nomenclature."
   ],
   "id": "adc2ca842781247e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<center>\n",
    "\n",
    "![](minimal_workflow.png)\n",
    "\n",
    "</center>"
   ],
   "id": "a44b3bbebf20ba08"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We have already loaded the raw data file used in this minimal example into our working directory.\n",
    "\n",
    "As you can see, the `plot_benchmark` rule will be called twice with two different filename extensions. For this, we are taking advantage of the concept of wildcards (`ext`). Snakemake will automatically resolve the wildcards using the dependency graph. In this case, the `all` rule takes as input both a `png` and a `pdf` figure which propagates back throughout the workflow."
   ],
   "id": "bb8bea134557dff0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### The `Snakefile` and `rules`",
   "id": "8eaffe3a0309e7f5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The rules need to be defined in a so-called `Snakefile` that sits in your current working directory. For our minimal example the `Snakefile` looks like this:",
   "id": "7d6c3496921b48f1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "Code(filename=\"Snakefile\", language=\"Python\")",
   "id": "3c9bd005c5532383",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "You can check out the scripts under `scripts`. You will see that they are simplistic and only serve an illustrative purpose.\n",
    "\n",
    "You can also observe how the `plot_benchmark` rule is defined to take advantage of the wildcards. This reduces the redundancy in the `Snakefile`. Wildcards are defined between `{ }` in the rule definition."
   ],
   "id": "6c70342f61457e56"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Calling a workflow",
   "id": "a2f47bc7af5fb49f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "You can trigger the workflow by specifying a target file, like `data/benchmark.pdf`, or any intermediate file:\n",
    "```bash\n",
    "snakemake -call data/benchmark.pdf\n",
    "```"
   ],
   "id": "4a9a23d9e767f9cf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Alternatively, you can also execute the workflow by calling a rule that produces an intermediate file:\n",
    "```bash\n",
    "snakemake -call build_data\n",
    "```\n",
    "**NOTE:** You cannot call a rule that includes a wildcard without specifying what the wildcard should be filled with. Otherwise, Snakemake will not know what to propagate back."
   ],
   "id": "d6442b964a93de4d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Or you can call the common rule `all` which can be used to execute the entire workflow. It takes the final workflow output as its input and thus requires all previous dependent rules to be run as well:\n",
    "```bash\n",
    "snakemake -call all\n",
    "```\n",
    "\n",
    "Because we defined the `all` rule as first in the `Snakefile`, this rule is assumed to be the default and the following also works:\n",
    "```bash\n",
    "snakemake -call\n",
    "```"
   ],
   "id": "73c326553dc384b2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "A very important feature is the `-n` flag which executes a `dry-run`. It is recommended to always first execute a `dry-run` before the actual execution of a workflow. This simply prints out the DAG of the workflow to investigate without actually executing it.\n",
    "\n",
    "Let's try this out and investigate the output:"
   ],
   "id": "f5ff4b388cc07334"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "! snakemake -call -n",
   "id": "7625e4178e3bc465",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "As you can see, the `plot_benchmark` rule will be executed twice due to wildcards.",
   "id": "175a00305d1cc4f3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Visualizing the `DAG` of a workflow",
   "id": "d9d8f1407d493fa8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "You can also visualize the DAG of jobs using the `--dag` flag and the Graphviz `dot` command. This will not run the workflow but only create the visualization:",
   "id": "21e7a3629ef0cdee"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "! snakemake -call --dag | sed -n \"/digraph/,\\$p\" | dot -Tpng > dag_minimal.png\n",
    "# For Windows run instead:\n",
    "# ! snakemake -call --dag | Out-String | ForEach-Object { $_ -replace '(?s)^.*?(digraph)', '$1' } | dot -Tpng -o dag_minimal.png"
   ],
   "id": "7ccdab94c8bd145b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "Image(\"dag_minimal.png\")",
   "id": "a4458c2fb4ff3fe0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Rules that need to be executed will be presented as plain lines, while those that have already been executed will be presented as dotted lines. An alternative to the DAG is the `rulegraph`. This graph is typically less crowded as you will only visualize the dependency graph of rules. This representation is leaner than the DAG because rules are not repeated for wildcards.",
   "id": "fb36ef57524378b5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "! snakemake -call all --rulegraph | sed -n \"/digraph/,\\$p\" | dot -Tpng > rulegraph_minimal.png\n",
    "# For Windows run instead:\n",
    "# ! snakemake -call all --rulegraph | Out-String | ForEach-Object { $_ -replace '(?s)^.*?(digraph)', '$1' } | dot -Tpng -o rulegraph_minimal.png"
   ],
   "id": "9b9065a9e4c5b046",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "Image(\"rulegraph_minimal.png\")",
   "id": "1d83315b8dbd385e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "As you can see, the `plot_benchmark` rule is only represented once.\n",
    "\n",
    "Alternatively, you can also visualize a `filegraph`, which is similar to the `rulegraph` but includes some information about the inputs and outputs to each of the rules."
   ],
   "id": "40d20a068d2559bd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "! snakemake -call all --filegraph | sed -n \"/digraph/,\\$p\" | dot -Tsvg > filegraph_minimal.svg\n",
    "# For Windows run instead:\n",
    "# ! snakemake -call all --filegraph | Out-String | ForEach-Object { $_ -replace '(?s)^.*?(digraph)', '$1' } | dot -Tsvg -o filegraph_minimal.svg"
   ],
   "id": "8ba6ef094406650b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "SVG(\"filegraph_minimal.svg\")",
   "id": "710d577c4146acb6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Task 1: Executing a workflow with Snakemake\n",
    "\n",
    "**a)** For our minimal example, execute a `dry-run` to produce the intermediate file `data/base_2030.nc`.\n",
    "\n",
    "**b)** Execute the entire workflow and investigate what happens if you try to execute the workflow again.\n",
    "\n",
    "**c)** Delete the final output file `data/benchmark.pdf` and investigate what happens if you try to execute the workflow again.\n",
    "\n",
    "**d)** Change a value in the raw input data file `data/data_raw.csv` and save it again, overwriting the original file. Investigate what happens if you try to execute the workflow again.\n",
    "\n",
    "Hint: You can also just `touch` the file by executing `Path(\"data/data_raw.csv\").touch()`. This will mimic a file edit.\n",
    "\n",
    "**e)** (Optional) Open the `Snakefile` and add a second rule that processes the file `data_raw_2.csv` using the same script as the `build_data` rule. Add the output of this new rule as a second input to the `prepare_network` rule."
   ],
   "id": "dda167b196d3e12"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# Your solution a)",
   "id": "bb94ee10455045f4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# Your solution b)",
   "id": "90bfb4d25f2bf425",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# Your solution c)",
   "id": "af424d24581ae431",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# Your solution d)",
   "id": "4e731efe45b7bab4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# Your solution e)",
   "id": "6251241740ebb761",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Discover Open-TYNDP file structure",
   "id": "d56d1d7924072f3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We have already retrieved a prebuilt version of the `open-tyndp` GitHub repository into our working directory. This folder contains a run of Open-TYNDP for NT and DE scenarios, with 2030 and 2040 as planning horizons. We removed the atlite cutout from the archive and compressed the archive using `zip -r open-tyndp.zip .`.",
   "id": "ba775868587ae888"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The `open-tyndp` repository contains the following structure. Directories of particular interest are marked in bold:",
   "id": "8286484ea49a6273"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- **benchmarks**: will store Snakemake benchmarks (does not exist initially)\n",
    "- **config**: configurations used in the study\n",
    "- cutouts: will store raw weather data cutouts from atlite (does not exist initially)\n",
    "- **data**: includes input data that is not produced by any Snakemake rule. Various different input files are retrieved from external storage and stored in this directory\n",
    "- doc: includes all files necessary to build the readthedocs documentation of PyPSA-Eur\n",
    "- **envs**: includes all the mamba environment specifications to run the workflow\n",
    "- logs: will store log files (does not exist initially)\n",
    "- notebooks: includes all the notebooks used for ad-hoc analysis\n",
    "- report: contains all files necessary to build the report; plots and result files are generated automatically\n",
    "- **rules**: includes all the Snakemake rules loaded in the Snakefile\n",
    "- **resources**: will store intermediate results of the workflow which can be picked up again by subsequent rules (does not exist initially)\n",
    "- **results**: will store the solved PyPSA network data, summary files and output plots (does not exist initially)\n",
    "- **scripts**: includes all the Python scripts executed by the Snakemake rules to build the model"
   ],
   "id": "7e0cd6fb9a65dce6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Task 2: Explore the folder\n",
    "\n",
    "**a)** Can you find the TYNDP specific data input files?\n",
    "\n",
    "**b)** Where can you check which scenario and planning horizons were used to generate the current results?\n",
    "\n",
    "Hint: Search for `config.tyndp.yaml`.\n",
    "\n",
    "**c)** Can you find the hydrogen grid map in the output files for the NT scenario in 2040?\n",
    "\n",
    "Hint: Search for `base_s_all__-h2_network_2040.pdf`."
   ],
   "id": "b2676d0d114a1be3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# Your solution a)",
   "id": "73fdc98fc6d8bf59",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# Your solution b)",
   "id": "de6d6620d8aaa0a5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# Your solution c)",
   "id": "1f08f2445619b85a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Using Snakemake to launch the Open-TYNDP workflow",
   "id": "7ed0260a471e343d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We now need to change our working directory to the Open-TYNDP directory we previously retrieved.",
   "id": "9965703b78d4a79"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "os.chdir(\"data/open-tyndp\")",
   "id": "c8223c68c7aa4ecd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Be aware that to run the previous section of this notebook, you will need to restore the default working directory using `os.chdir(\"../../\")`.\n",
    "\n",
    "Let's check that we are indeed in the new directory now:"
   ],
   "id": "ca4deea80e15f120"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "os.getcwd()",
   "id": "1cdd31701c6947c6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We can now use Snakemake to call some of the rules to produce outputs with the `open-tyndp` PyPSA model. \n",
    "\n",
    "We will use the prepared TYNDP configuration file (`config/config.tyndp.yaml`) and schedule a dry-run with `-n` as we only want to investigate the DAG of the workflow:"
   ],
   "id": "781b4d5b2cd5f9dd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "! snakemake -call --configfile config/config.tyndp.yaml -n",
   "id": "6d345ee60a061303",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "As you can see, there is nothing to be done since all necessary outputs are already present in the files. However, we can still explore the set of rules defined in the `Snakefile` and the other `.smk` files. First, we can plot the rule graph, then the full DAG.\n",
    "\n",
    "The corresponding rule graph to this workflow will look like this:"
   ],
   "id": "b1253e15c0be44"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "! snakemake -call --configfile config/config.tyndp.yaml --rulegraph | sed -n \"/digraph/,\\$p\" | dot -Tpng > rulegraph_open_tyndp.png\n",
    "# For Windows run instead:\n",
    "# ! snakemake -call --configfile config/config.tyndp.yaml --rulegraph | Out-String | ForEach-Object { $_ -replace '(?s)^.*?(digraph)', '$1' } | dot -Tpng -o rulegraph_open_tyndp.png"
   ],
   "id": "2652bd1479d1aa1d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "Image(\"rulegraph_open_tyndp.png\")",
   "id": "519f591cdbf9f4b0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The corresponding DAG to this workflow will look like this:",
   "id": "4647488b0cbcf503"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "! snakemake -call --configfile config/config.tyndp.yaml --dag | sed -n \"/digraph/,\\$p\" | dot -Tpng > dag_open_tyndp.png\n",
    "# For Windows run instead:\n",
    "# ! snakemake -call --configfile config/config.tyndp.yaml --dag | Out-String | ForEach-Object { $_ -replace '(?s)^.*?(digraph)', '$1' } | dot -Tpng -o dag_open_tyndp.png"
   ],
   "id": "31ec7cef85aeb387",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "Image(\"dag_open_tyndp.png\")",
   "id": "c855e3511ce7cff5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "As you can see, this workflow is much more complex than our minimal example from the beginning. Since we already executed the entire workflow for this demonstration, all the rules are presented as dotted lines in the DAG.\n",
    "\n",
    "You will also notice that the DAG is much larger than the rule graph. This is because Open-TYNDP leverages wildcards quite extensively to generalize rule definitions and to parallelize tasks.\n",
    "\n",
    "Nevertheless, the general idea remains the same. We retrieve data which we consequently process, then we prepare the model network and we solve it before we postprocess the results (summary, plotting, benchmarks)."
   ],
   "id": "81164d2fba4c2378"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Triggering a workflow run on Open-TYNDP\n",
    "\n",
    "Let's simulate a completed optimization by updating the timestamp of the solved network file (base_s_all___2040.nc), which is saved as the final step of the optimization process."
   ],
   "id": "cb4dd932fd7dedcb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "Path(\"results/tyndp/NT/networks/base_s_all___2040.nc\").touch()",
   "id": "aa6f23eee5e90015",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can now see that Snakemake triggers all the rules that depend on the solved network. In this case, these are all the postprocessing rules.",
   "id": "1e4d0af6f8873e5e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "! snakemake -call --configfile config/config.tyndp.yaml -n",
   "id": "10db0a3156a02940",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    ":::{note}\n",
    "Because of the complexity of the workflow, we are not executing this. However, if you are running this notebook on your local machine, you can also use the `conda` package manager to install the `pypsa-eur` environment and run the workflow instead of dry-runs:\n",
    "```\n",
    "conda env create --file envs/<YourSystemOS>.lock.yaml\n",
    "```\n",
    ":::"
   ],
   "id": "4799dee6b5391997"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Update on new features",
   "id": "c3645e00822ebe82"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "This workshop focuses on the 2030 NT scenario and the 2040 DE scenario. Since our last workshop, we have added four major features to the model:\n",
    "1. TYNDP electricity demand and PECD capacity factors time series,\n",
    "2. Onshore wind and solar TYNDP technologies (incl. PEMMDB existing capacities and trajectories),\n",
    "3. Offshore hubs (incl. the offshore topology, all associated technologies, potential constraints and trajectories),\n",
    "4. Hydrogen import corridors."
   ],
   "id": "ac9f0c8aa4bb5c2e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The Open-TYNDP data we retrieved contains networks with low time resolution (6H). This is illustrative; however, since we are focusing on time series, we will use another network with hourly resolution. We will import this pre-solved network for NT 2030.",
   "id": "3229052dffbf7a17"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "n_NT_2030h = pypsa.Network(\"../network_NT_presolve_highres_2030.nc\")",
   "id": "5b75af3aace6db3e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Electricity demand profiles",
   "id": "480c23436c2e451c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can then explore the electricity demand profiles that are attached to the network. Can you remember how to access time-varying attributes of components in PyPSA?",
   "id": "659793c1c74d263b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "loads_2030 = n_NT_2030h.loads_t.p_set\n",
    "loads_2030.head()"
   ],
   "id": "ad289a7a8b685d0c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's plot the electricity demand time series:",
   "id": "65759acb0e89198"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, ax = plt.subplots()\n",
    "loads_2030.div(1e3).plot(\n",
    "    xlabel=\"Time\",\n",
    "    ylabel=\"Load [GW]\",\n",
    "    title=\"Electricity Load Time Series - NT - 2030\",\n",
    "    grid=True,\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "ax.legend(loc=\"upper center\", bbox_to_anchor=(0.5, -0.15), ncols=10)\n",
    "ax.grid(True, linestyle=\"--\");"
   ],
   "id": "343e43691216daea",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This is very overwhelming to look at. Let's filter that down a bit...",
   "id": "2f111a6e577b2717"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Group country profiles together and select a week\n",
    "country_mapping = n_NT_2030h.buses.query(\"carrier=='AC'\").country\n",
    "loads_2030_by_country = (\n",
    "    n_NT_2030h.loads_t.p_set.T.rename(country_mapping, axis=0)\n",
    "    .groupby(\"Load\")\n",
    "    .sum()\n",
    "    .T.loc[\"2009-03-01\":\"2009-03-07\", [\"FR\", \"DE\", \"GB\"]]\n",
    ")\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots()\n",
    "loads_2030_by_country.div(1e3).plot(\n",
    "    xlabel=\"Time\",\n",
    "    ylabel=\"Load [GW]\",\n",
    "    title=\"Electricity Load Time Series - NT - 2030\",\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "ax.grid(True, linestyle=\"--\")\n",
    "ax.legend();"
   ],
   "id": "baabd4710274a527",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "As you might remember, we can also use the **PyPSA Statistics** module that we introduced in the last workshop to interactively visualize these electricity demand inputs from the network. For this to work, we need a solved network.\n",
    "\n",
    "Let's load our pre-solved networks, so we can use the statistics module to analyze it."
   ],
   "id": "b1799cc70ce90a5e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Import networks\n",
    "n_NT_2030 = pypsa.Network(\"results/tyndp/NT/networks/base_s_all___2030.nc\")\n",
    "n_DE_2040 = pypsa.Network(\"results/tyndp/DE/networks/base_s_all___2040.nc\")\n",
    "\n",
    "# Fix missing colors\n",
    "n_NT_2030.carriers.loc[\"none\", \"color\"] = \"#000000\"\n",
    "n_NT_2030.carriers.loc[\"\", \"color\"] = \"#000000\"\n",
    "n_DE_2040.carriers.loc[\"none\", \"color\"] = \"#000000\"\n",
    "n_DE_2040.carriers.loc[\"\", \"color\"] = \"#000000\""
   ],
   "id": "58e1023aa53efe5d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Let's define helper variables\n",
    "s_NT_2030 = n_NT_2030.statistics\n",
    "s_DE_2040 = n_DE_2040.statistics"
   ],
   "id": "837fd0695272e345",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's access the load data using `statistics.withdrawal()`. The electricity load is attached to the `low voltage` buses.",
   "id": "2ba7da4baae4b3c6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "s_NT_2030.withdrawal(\n",
    "    bus_carrier=\"low voltage\", comps=\"Load\", aggregate_time=False, groupby=False\n",
    ").T.head()"
   ],
   "id": "49d634f33e661124",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "As previously, we can plot all the countries at the same time, but now using the `statistics` module...",
   "id": "c6548286e9c76a87"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, ax, facet_grid = s_NT_2030.withdrawal.plot.line(\n",
    "    bus_carrier=\"low voltage\",\n",
    "    y=\"value\",\n",
    "    x=\"snapshot\",\n",
    "    color=\"country\",\n",
    ")\n",
    "\n",
    "fig.set_size_inches(14, 7)\n",
    "fig.suptitle(\"Electricity demand Time Series - NT - 2030\", y=1.05)\n",
    "\n",
    "ax.set_ylabel(\"Load [MW]\")\n",
    "ax.set_xlabel(\"Time\");"
   ],
   "id": "60bb8511438ad134",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "However, plotting individual countries is now easier. Let's present two countries.",
   "id": "5dad91d88fe07c30"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, ax, facet_col = s_NT_2030.withdrawal.plot.area(\n",
    "    bus_carrier=\"low voltage\",\n",
    "    y=\"value\",\n",
    "    x=\"snapshot\",\n",
    "    color=\"carrier\",\n",
    "    stacked=True,\n",
    "    facet_row=\"country\",\n",
    "    query=\"carrier == 'electricity' and country in ['DE', 'FR']\",\n",
    "    figsize=(14, 7),\n",
    ")\n",
    "\n",
    "fig.suptitle(\"Electricity demand Time Series - NT - 2030\", y=1.05)\n",
    "\n",
    "ax[0, 0].set_ylabel(\"Load [MW]\")\n",
    "ax[1, 0].set_ylabel(\"Load [MW]\")\n",
    "ax[1, 0].set_xlabel(\"Time\");"
   ],
   "id": "fe9a946afb7c8acd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "As you can see, the statistics module is a powerful tool to explore your results. You can find more information about it in the [first workshop notebook](20250409-workshop-pypsa-01.ipynb#extracting-insights-visualization) and in the official [PyPSA documentation](https://docs.pypsa.org/latest/user-guide/plotting/charts/).",
   "id": "1829950b1c6f15c8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## PECD capacity factors",
   "id": "88dd4a4679e527df"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The Pan-European Climate Database (PECD) provides capacity factor profiles for all the different renewable technologies used in the TYNDP. We processed these input data files into a Python and PyPSA friendly input format.\n",
    "\n",
    "Let's start by looking at the processed capacity factor time series for Solar PV Rooftop for 2030. These processed data are stored in the `resources` directory, as they are an output of `build_renewable_profiles_pecd`. We will filter the data to a set of countries and a week."
   ],
   "id": "dd89146cbe6742a7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cf_pv_rftp = pd.read_csv(\n",
    "    \"resources/tyndp/NT/pecd_data_LFSolarPVRooftop_2030.csv\",\n",
    "    index_col=0,\n",
    "    parse_dates=True,\n",
    ").loc[\"2009-07-01\":\"2009-07-04\", [\"SE04\", \"DE00\", \"FR00\", \"ES00\"]]\n",
    "cf_pv_rftp.head(10)"
   ],
   "id": "28e1db240e46cb80",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Using a heatmap, we can better grasp the content of the data.",
   "id": "d4008d4a763b2c75"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, ax = plt.subplots()\n",
    "sns.heatmap(cf_pv_rftp.T, cmap=\"viridis\", cbar_kws={\"label\": \"Capacity Factor\"}, ax=ax)\n",
    "\n",
    "ax.set_title(\"Capacity Factor Time Series - NT - 2030 - March 1-4\")\n",
    "tick_positions = range(0, len(cf_pv_rftp), 24)\n",
    "ax.set_xticks(tick_positions)\n",
    "ax.set_xticklabels(\n",
    "    cf_pv_rftp.index[tick_positions].strftime(\"%Y-%m-%d\"), rotation=45, ha=\"right\"\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"Time\")\n",
    "ax.set_ylabel(\"Node\");"
   ],
   "id": "667d5e06e3a353ab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can also present the data in a line plot.",
   "id": "f0c345dd4928aa15"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "cf_pv_rftp.plot(\n",
    "    title=\"Capacity Factor Time Series - NT - 2030 - March 1-4\",\n",
    "    xlabel=\"Date\",\n",
    "    ylabel=\"Capacity Factor\",\n",
    "    ax=ax,\n",
    ");"
   ],
   "id": "c32f92d5829267dd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Task 3: Compute average capacity factor\n",
    "\n",
    "**a)** Locate the resource file with onshore wind capacity factors used for NT in 2030.\n",
    "\n",
    "**b)** Compute the average onshore wind capacity factor for all the countries in the PECD.\n",
    "\n",
    "**c)** Verify one of the values directly in the network.\n",
    "\n",
    "Hint: Capacity factors are defined as time-varying parameters of generators and are called `p_max_pu`."
   ],
   "id": "7134e2ff9f461410"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# Your solution a)",
   "id": "fa4e4470970b4986",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# Your solution b)",
   "id": "9f0c696f967dd83e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# Your solution c)",
   "id": "45be11aa3d28a0c0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Onshore wind and solar",
   "id": "be8340e94be30bfe"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The TYNDP provides existing capacities with the Pan-European Market Modelling database (PEMMDB) and expansion trajectories for given investment candidates and expandable technologies. For the implemented onshore wind and solar technologies, these have been included in beta release v0.3 of the Open-TYNDP model.\n",
    "\n",
    "It is possible to retrieve those values from the networks as they are added as `p_nom_min` and `p_nom_max` of the generators. However, for simplicity, we will import the values directly from the processed input files for the DE scenario. This allows us to investigate the entire trajectory path at once instead of reading one network per planning horizon."
   ],
   "id": "ae6acac38f650e5a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "trj = pd.read_csv(\"resources/tyndp/DE/tyndp_trajectories.csv\", index_col=0)\n",
    "trj.head()"
   ],
   "id": "1ca3d2c29a288f06",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Similar to the capacity factor time series, we want to focus on the Solar PV Rooftop technology and its trajectory path. Let's take Germany (DE00) to investigate.",
   "id": "917ec70e212f0614"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "trj_pv_rftp_de = (\n",
    "    trj.query(\"carrier == 'solar-pv-rooftop' and bus == 'DE00'\")\n",
    "    .sort_values(by=\"pyear\")\n",
    "    .set_index(\"pyear\")[[\"p_nom_min\", \"p_nom_max\"]]\n",
    "    .div(1e3)  # GW\n",
    ")\n",
    "trj_pv_rftp_de"
   ],
   "id": "8f2a4b1a12553ff7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now that we have collected the data, we can create a nice visualization of it.",
   "id": "6b01fcba4ac6f8f7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, ax = plt.subplots()\n",
    "trj_pv_rftp_de.plot(\n",
    "    title=\"Solar PV Rooftop Capacity Trajectories - DE scenario - DE00\",\n",
    "    xlabel=\"Planning Year\",\n",
    "    ylabel=\"Capacity [GW]\",\n",
    "    color=[\"#E63946\", \"#1D3557\"],\n",
    "    style=\"*--\",\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "ax.fill_between(\n",
    "    trj_pv_rftp_de.index,\n",
    "    trj_pv_rftp_de.iloc[:, 0],\n",
    "    trj_pv_rftp_de.iloc[:, 1],\n",
    "    alpha=0.25,\n",
    "    color=\"#457B9D\",\n",
    "    label=\"Trajectory Range\",\n",
    ")\n",
    "\n",
    "ax.xaxis.set_major_locator(MultipleLocator(5))\n",
    "ax.set_xlim(trj_pv_rftp_de.index.min(), trj_pv_rftp_de.index.max())"
   ],
   "id": "d50e5819e0ed8da4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now, let's access the network for the DE scenario to compare one of these trajectory values for 2040.",
   "id": "275d4e44a9335a33"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "trj_pv_rftp_de_nc = (\n",
    "    n_DE_2040.generators.query(\"carrier == 'solar-pv-rooftop' and bus == 'DE00'\")\n",
    "    .sort_index()[[\"p_nom_opt\", \"p_nom_min\", \"p_nom_max\"]]\n",
    "    .div(1e3)  # in GW\n",
    ")\n",
    "trj_pv_rftp_de_nc"
   ],
   "id": "691e4a4fca1b009d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Assets remain in the PyPSA network throughout their entire operational lifetime. The year in an asset's name (e.g \"2030\") indicates its build year, not the cumulative capacity in that investment period.\n",
    "\n",
    "Example: In the 2040 planning year, your network contains:\n",
    "\n",
    "- Generators named \"2030\" (built in 2030, still operational)\n",
    "- Generators named \"2040\" (newly built in 2040)\n",
    "\n",
    "Each generator stores information that depends on its build year (such as efficiency and costs), and after optimization, it contains the cost-optimal capacity that is added in that specific year."
   ],
   "id": "859aee04d515826c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "As we can see, the `p_nom_min` and `p_nom_max` values for 2040 do not match the reported trajectory values above. The TYNDP trajectories are cumulative trajectories. This means that 2040 generators are bound to extend the optimal capacity of the still operational generators of 2030.\n",
    "\n",
    "Therefore, if we add the existing capacity (`p_nom_opt`) from 2030 to the `p_nom_min` and `p_nom_max` values from 2040, we will obtain the reported trajectory values shown above:"
   ],
   "id": "7fac17d9c05ddea7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "(\n",
    "    trj_pv_rftp_de_nc.loc[\"DE00 0 solar-pv-rooftop-2040\", [\"p_nom_min\", \"p_nom_max\"]]\n",
    "    + trj_pv_rftp_de_nc.loc[\"DE00 0 solar-pv-rooftop-2030\", \"p_nom_opt\"]\n",
    ")"
   ],
   "id": "11b3eef5efced6ca",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Task 4: Verify onshore wind trajectories\n",
    "\n",
    "Verify onshore wind trajectories in the network itself. \n",
    "\n",
    "Hint: This can be quick if you can copy and reuse the existing code used above."
   ],
   "id": "161b3c7d22997c7a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# Your solution",
   "id": "322c1b1e2cc7889e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Offshore Hubs",
   "id": "732240c6f106bad0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "To implement the offshore methodology, new carriers (*i.e.*, technologies) are introduced. All the offshore technologies start with `offwind`.",
   "id": "1427eeea9e161725"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "offwind_carriers = n_NT_2030.carriers.query(\"Carrier.str.contains('offwind')\")\n",
    "offwind_carriers_i = offwind_carriers.index\n",
    "offwind_carriers"
   ],
   "id": "5a4608400f32dae7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "As you can see in the table above, all the offshore technologies are implemented. We model technologies that are a combination of the following:\n",
    "- both `ac` and `dc` zones, as well as `h2` generating windfarms;\n",
    "- both fixed-bottom (`fb`) and floating (`fl`) foundations;\n",
    "- both radial (`r`) and hub (`oh`) connections."
   ],
   "id": "1d68001670f741f3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We also introduce new offshore buses, both for electricity and hydrogen. Electricity buses use `AC_OH` as the carrier, while hydrogen buses use `H2_OH`.",
   "id": "df9a21284dbd9376"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "n_NT_2030.buses.query(\"carrier.str.contains('OH')\").head()",
   "id": "a512547e88c04490",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's narrow down this list to a single country.",
   "id": "933e09616a7a4f86"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "buses = n_NT_2030.buses.query(\"carrier.str.contains('OH') and country=='BE'\")\n",
    "buses_i = buses.index\n",
    "buses"
   ],
   "id": "eddce2162828fef9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Using `n.plot.explore()`, we can easily get an overview of the network topology. Let's clean the network before exploring it to only focus on the electrical offshore topology.",
   "id": "b646fd26aba561c8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "n_explore_ac_oh = n_NT_2030.copy()\n",
    "n_explore_ac_oh.remove(\n",
    "    \"Bus\", n_explore_ac_oh.buses.query(\"carrier not in ['AC_OH']\").index\n",
    ")\n",
    "n_explore_ac_oh.plot.explore()"
   ],
   "id": "d859d18690e9943",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now, we can search the network for generators that are defined with those carriers.",
   "id": "762f1cdc51f88a4e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "n_NT_2030.generators.query(\"carrier in @offwind_carriers_i\").head()",
   "id": "2d41119678d2eda2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's focus on a specific country:",
   "id": "39545e1139ab7fe4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "n_NT_2030.generators.query(\"carrier in @offwind_carriers_i and bus in @buses_i\")",
   "id": "1db8d8c23a7e6d7b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Task 5: Extract existing offshore capacities\n",
    "\n",
    "Extract existing offshore capacities for the country of your choice using the statistics module."
   ],
   "id": "9c3159648f45b0af"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# Your solution",
   "id": "5d357c708ae59202",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can also explore the data with the statistics module. First, we can create bar charts.",
   "id": "fec0c440b061a7d1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, ax, facet_grid = s_DE_2040.optimal_capacity.plot.bar(\n",
    "    bus_carrier=[\"AC\", \"AC_OH\", \"H2_OH\"],\n",
    "    query=\"carrier.str.startswith('offwind') and country in ['NL', 'GB']\",\n",
    "    facet_col=\"country\",\n",
    ")\n",
    "fig.suptitle(\"Offshore wind capacities - DE - 2040\", y=1.05);"
   ],
   "id": "885e698fcef109bf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Then, we can create maps.",
   "id": "9e10560464560b2b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Let's clean a network copy to only keep offshore data\n",
    "n_map = n_DE_2040.copy()\n",
    "n_map.remove(\"Bus\", n_map.buses.query(\"carrier not in ['AC', 'AC_OH', 'H2_OH']\").index)\n",
    "n_map.remove(\n",
    "    \"Generator\", n_map.generators.query(\"not carrier.str.startswith('offwind')\").index\n",
    ")\n",
    "n_map.remove(\"Link\", n_map.links.index)\n",
    "n_map.remove(\"StorageUnit\", n_map.storage_units.index)"
   ],
   "id": "2ac1cf9f350693b1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define map projection\n",
    "def load_projection(plotting_params):\n",
    "    proj_kwargs = plotting_params.get(\"projection\", dict(name=\"EqualEarth\"))\n",
    "    proj_func = getattr(ccrs, proj_kwargs.pop(\"name\"))\n",
    "    return proj_func(**proj_kwargs)\n",
    "\n",
    "\n",
    "proj = load_projection(dict(name=\"EqualEarth\"))"
   ],
   "id": "4019768c5e3bfa5f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create the map\n",
    "subplot_kw = {\"projection\": proj}\n",
    "fig, ax = plt.subplots(figsize=(9, 9), subplot_kw=subplot_kw)\n",
    "n_map.statistics.optimal_capacity.plot.map(\n",
    "    bus_carrier=[\"AC\", \"AC_OH\", \"H2_OH\"],\n",
    "    ax=ax,\n",
    "    bus_area_fraction=0.006,\n",
    "    title=\"Offshore wind capacities - DE - 2040\",\n",
    "    legend_circles_kw=dict(\n",
    "        frameon=False,\n",
    "    ),\n",
    ");"
   ],
   "id": "ea4ab7f7a7224f82",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "On the map above, we can see the two types of offshore wind connections. Radially connected capacities are attached to and plotted on the mainland node, hence offshore capacities \"on land\". In contrast, offshore hub capacities are attached to and plotted on the actual offshore nodes.\n",
    "\n",
    "The NT scenario is a dispatch scenario. This is implemented in PyPSA using the argument `p_nom_extendable = False`. However, for the two other scenarios, we need to model capacity expansion. \n",
    "\n",
    "Currently, the model is configured to do myopic optimization. This means that only the capacities of the current planning horizon are expandable. Generators of the previous planning horizons are fixed at their optimal capacities. Let's verify this in the network."
   ],
   "id": "cd89337fb620b006"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Let's explore offshore wind generators in Denmark\n",
    "c_buses = n_DE_2040.buses.query(\"country == 'DK'\").index\n",
    "(\n",
    "    n_DE_2040.generators.query(\"carrier in @offwind_carriers_i and bus in @c_buses\")[\n",
    "        [\n",
    "            \"build_year\",\n",
    "            \"p_nom\",\n",
    "            \"p_nom_min\",\n",
    "            \"p_nom_max\",\n",
    "            \"p_nom_opt\",\n",
    "            \"p_nom_extendable\",\n",
    "        ]\n",
    "    ].sort_values(by=\"build_year\")\n",
    ")"
   ],
   "id": "d630c13be6b1f01b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "You can see multiple columns in the table:\n",
    "- `build_year`, the build year of the asset (input)\n",
    "- `p_nom`, the nominal power (input)\n",
    "- `p_nom_min`, if expansion is enabled, the minimum value of the nominal capacity (input)\n",
    "- `p_nom_max`, if expansion is enabled, the maximum value of the nominal capacity (input)\n",
    "- `p_nom_opt`, the optimized nominal capacity (output)\n",
    "- `p_nom_extendable`, if expansion is enabled for that asset (input)\n",
    "\n",
    "The `p_nom_min` reflects the existing capacities defined in the TYNDP, while the `p_nom_max` represents the layer potential. We also implemented constraints to ensure we respect the zone potentials and the trajectories defined in the data:\n",
    "- A constraint limits the expansion of DC and H2 sitting on the same location, as the sum of the two capacities cannot exceed the layer potential.\n",
    "- A constraint sets the maximum potential per zone, taking into account the zone trajectories."
   ],
   "id": "fbc0ae9c2f2d236c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## H2 imports",
   "id": "78cde199adef46bb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "There have also been some important additions to the H2 infrastructure since our last workshop. The different H2 import corridors are now included in the model with a simple pipeline transport representation, similar to the H2 reference grid.\n",
    "\n",
    "The import pipelines are implemented using PyPSA's link component. As is convention in PyPSA, this means `bus0` represents the external import node and `bus1` the importing country's Hydrogen Zone 2 node.\n",
    "\n",
    "We can investigate our NT network and list the importing nodes."
   ],
   "id": "df459efbc90a6a41"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "h2_import = n_NT_2030.links.filter(like=\"H2 import\", axis=0)\n",
    "set(h2_import.bus1)"
   ],
   "id": "5406eeb9622ed4b0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "As we can see from the `p_nom_extendable` attribute of these links, the H2 import corridors cannot be endogenously expanded by the model but are rather fixed inputs as in the TYNDP 2024 methodology.",
   "id": "f9e422c5ca2d0fac"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "h2_import.p_nom_extendable.all()",
   "id": "2d940401a8409df7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "h2_import[[\"bus0\", \"bus1\", \"carrier\", \"p_nom_extendable\"]].head()",
   "id": "d6b20ba1c52bd5cd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can investigate our DE network to create a similar plot to what we created last time. Let's import some handy plotting functions from the open-tyndp workflow for this:",
   "id": "5251f969d504abca"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# It is generally NOT a recommended practice to ignore deprecation warnings.\n",
    "# However, for the purposes of this workshop, we will make use of it to make our output less noisy\n",
    "warnings.filterwarnings(action=\"ignore\", category=DeprecationWarning)\n",
    "from scripts.plot_base_hydrogen_network import plot_h2_map_base"
   ],
   "id": "6ad98b54263178e8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "And plot the H2 reference grid together with the import corridors:",
   "id": "e9c1388ac54314e0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "warnings.filterwarnings(action=\"ignore\", category=DeprecationWarning)\n",
    "map_opts = {\n",
    "    \"boundaries\": [-11, 30, 28, 71],\n",
    "    \"geomap_colors\": {\n",
    "        \"ocean\": \"white\",\n",
    "        \"land\": \"white\",\n",
    "    },\n",
    "}\n",
    "\n",
    "plot_h2_map_base(\n",
    "    network=n_DE_2040,\n",
    "    map_opts=map_opts,\n",
    "    map_fn=\"../../../h2_import_corridors_DE2040.png\",\n",
    ")\n",
    "Image(\"../../../h2_import_corridors_DE2040.png\")"
   ],
   "id": "34baee81ef07fed3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Task 6: Investigate H2 import corridors",
   "id": "33daa6559fb19787"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    " **a)** Extract and investigate the different import corridors for one specific country of your choice using our NT 2030 network.\n",
    "\n",
    " **b)** Compare with DE 2040 data."
   ],
   "id": "b895e837847999d1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# Your solution a)",
   "id": "c733460e25c83e81",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# Your solution b)",
   "id": "33297cc3d32ff10a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Benchmarking framework",
   "id": "d50d97606399d09d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Open-TYNDP introduces a benchmarking framework for continuous and systematic validation of Open-TYNDP model outputs against TYNDP 2024 scenarios. This framework provides flexible and scalable validation across multiple metrics and benchmarking methods.\n",
    "\n",
    "Comprehensive documentation of the framework can be found in the [documentation](https://open-tyndp.readthedocs.io/en/latest/benchmarking.html)."
   ],
   "id": "73b07b3be184d66f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Metrics\n",
    "\n",
    "The following metrics from the [TYNDP 2024 Scenarios](https://2024.entsos-tyndp-scenarios.eu/wp-content/uploads/2025/01/TYNDP_2024_Scenarios_Report_FInal_Version_250128_web.pdf) report are considered relevant for benchmarking:\n",
    "\n",
    "- Exogenous Inputs:\n",
    "    - Benchmark Final Energy demand by fuel, EU27 (TWh), (Fig 5, p24 and Fig 51, p63)\n",
    "    - Benchmark Electricity demand per sector, EU27 (TWh), (Fig 6, p25 and Fig 52, p63)\n",
    "    - Benchmark Methane demand by sector, EU27 (TWh), (Fig 8, p27 and Fig 53, p64)\n",
    "    - Benchmark Hydrogen demand by sector, EU27 (TWh), (Fig 10, p28 and Fig 54, p64)\n",
    "- Investment and dispatch modelling outputs:\n",
    "    - Benchmark of net installed capacity for electricity generation, EU27 (GW), (Fig 25, p39 and Fig 55, p65)\n",
    "    - Benchmark of electricity generation, EU27 (TWh), (Fig 26, p39 and Fig 56, p65)\n",
    "    - Benchmark methane supply, EU27 (TWh), (Fig 32, p45 and Fig 57, p66)\n",
    "    - Benchmark hydrogen supply, EU27 (TWh), (Fig 33, p46 and Fig 58, p67)\n",
    "    - Benchmark biomass supply, EU27 (TWh), (Fig 59, p67)\n",
    "    - Benchmark energy imports, EU27 (TWh), (Fig 40, p51 and Fig 60, p68)\n",
    "    - Hourly generation profile of power generation, Fig 30, p35\n"
   ],
   "id": "c0a40e777872dc61"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The benchmarking is based on a methodology proposed by [Wen et al. (2022)](https://www.sciencedirect.com/science/article/pii/S0306261922011667). This methodology provides a multi-criteria approach to ensure: diversity, effectiveness, robustness, and compatibility.\n",
    "\n",
    "This methodology defines the following indicators:\n",
    "- **Missing**: Count of carriers/sectors dropped due to missing values\n",
    "- **sMPE** (Symmetric Mean Percentage Error): Indicates the direction of the deviation between modeled scenarios and TYNDP 2024 outcomes, showing if the output is overall overestimated or underestimated.\n",
    "- **sMAPE** (Symmetric Mean Absolute Percentage Error): Indicates the absolute magnitude of the deviations, avoiding the cancellation of negative and positive errors.\n",
    "- **sMdAPE** (Symmetric Median Absolute Percentage Error): Provides skewness information to complement sMAPE.\n",
    "- **RMSLE** (Root Mean Square Logarithmic Error): Complements the percentage errors since it shows the logarithmic deviation values.\n",
    "- **Growth error**: Shows the error on the temporal scale (i.e., between planning horizons). This indicator is ignored for dynamic time series (i.e., hourly generation profiles).\n"
   ],
   "id": "162f5e94a7b41ca7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Outputs",
   "id": "74411d57f3a9a3d0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    ":::{warning}\n",
    "Open-TYNDP is under active development and is not yet feature-complete. The current [development status](https://open-tyndp.readthedocs.io/en/latest/index.html#development-status) and the general [Limitations](https://open-tyndp.readthedocs.io/en/latest/limitations.html) are important to understand before assessing the current benchmarking results.\n",
    ":::\n",
    "\n",
    "We can now explore the content of the `results/tyndp/<SCENARIO>/validation` folder. It's in this folder that all the benchmarking data is stored. First, let's have a look at the summary figure. This figure presents the magnitude of the error for all indicators."
   ],
   "id": "d6402a39d6e69ea3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "display(\n",
    "    convert_from_path(\"results/tyndp/NT/validation/kpis_eu27_s_all___all_years.pdf\")[0]\n",
    ")"
   ],
   "id": "48f5b54332814211",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Associated with this figure, a table presents all the indicators for each metric.",
   "id": "2f666f047aea3df8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "pd.read_csv(\"results/tyndp/NT/validation/kpis_eu27_s_all___all_years.csv\", index_col=0)",
   "id": "d6e7e4ad786becbb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Note that figures and tables will always include a version tag (in this case `v0.2+gb9516f6f1`) to clearly identify the version of the codebase used to produce the validation.\n",
    "\n",
    "\n",
    "The same benchmarking information is available for all the metrics. Let's explore the quality of the power capacity metric."
   ],
   "id": "9e1175d6a2e9f2d9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "display(\n",
    "    convert_from_path(\n",
    "        \"results/tyndp/NT/validation/graphics_s_all___all_years/benchmark_power_capacity_eu27_cy2009_2030.pdf\"\n",
    "    )[0]\n",
    ")"
   ],
   "id": "d761be40790c2833",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Again, a table associated with the figure shows the detailed benchmarking data.",
   "id": "85e1ef56ac0b256e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "pd.read_csv(\n",
    "    \"results/tyndp/NT/validation/csvs_s_all___all_years/power_capacity_eu27_cy2009_s_all___all_years.csv\",\n",
    "    index_col=0,\n",
    ")"
   ],
   "id": "cb599f3f0313f152",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This feature is still work in progress and will be improved throughout the project.",
   "id": "73ee5211c2cefbbf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Solutions",
   "id": "7be4d766ffc76b0d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Task 1: Executing a workflow with Snakemake",
   "id": "7eb67aebefa79a63"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Solution a)\n",
    "# ! snakemake -call data/base_2030.nc -n"
   ],
   "id": "4aa0458fdec0e7f7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Solution b)\n",
    "# ! snakemake -call"
   ],
   "id": "13b47c75153826ec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Solution c)\n",
    "# ! snakemake -call"
   ],
   "id": "10fad796fe2f941",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Solution d)\n",
    "# Path(\"data/data_raw.csv\").touch()\n",
    "# ! snakemake -call"
   ],
   "id": "c4d2b270a9e00dd4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Solution e)\n",
    "# rule retrieve_data_2:\n",
    "#     input:\n",
    "#         \"data/data_raw.csv\"\n",
    "#     output:\n",
    "#         \"data/data_raw_2.csv\"\n",
    "#     shell:\n",
    "#         \"cp {input} {output}\"\n",
    "#\n",
    "# rule build_data_2:\n",
    "#     input:\n",
    "#         \"data/data_raw_2.csv\"\n",
    "#     output:\n",
    "#         \"data/data_filtered_2.csv\"\n",
    "#     script:\n",
    "#         \"scripts/build_data.py\"\n",
    "#\n",
    "# rule prepare_network:\n",
    "#     input:\n",
    "#         \"data/data_filtered.csv\",\n",
    "#         \"data/data_filtered_2.csv\"\n",
    "#     output:\n",
    "#         \"data/base_2030.nc\"\n",
    "#     script:\n",
    "#         \"scripts/prepare_network.py\""
   ],
   "id": "b440ba6b35de0278",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Task 2: Explore the folder",
   "id": "2c6fdb506d55a54e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Solution a)\n",
    "# data/tyndp_2024_bundle"
   ],
   "id": "f478b5893d0ce0ea",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Solution b)\n",
    "# config/config.tyndp.yaml"
   ],
   "id": "ffc498e37681afe8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Solution c)\n",
    "# results/tyndp/NT/maps/base_s_all__-h2_network_2040.pdf"
   ],
   "id": "46223c613ce70de3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Task 3: Compute average capacity factor",
   "id": "66acb05dc4025318"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Solution a)\n",
    "cf_onwind = pd.read_csv(\n",
    "    \"resources/tyndp/NT/pecd_data_Wind_Onshore_2030.csv\",\n",
    "    index_col=0,\n",
    "    parse_dates=True,\n",
    ")\n",
    "cf_onwind.head();"
   ],
   "id": "7b1e1918cf405f4f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Solution b)\n",
    "cf_onwind.columns = cf_onwind.columns.str[:2]\n",
    "cf_onwind.columns.name = \"country\"\n",
    "\n",
    "cf_onwind_sorted = cf_onwind.T.groupby(by=\"country\").mean().mean(axis=1).sort_values()\n",
    "cf_onwind_sorted.tail()"
   ],
   "id": "750a2d8d38dc794",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 9))\n",
    "cf_onwind_sorted.plot.barh(\n",
    "    title=\"Average capacity factors - 2030\",\n",
    "    xlabel=\"Capacity factor [p.u]\",\n",
    "    ylabel=\"Country\",\n",
    "    ax=ax,\n",
    ");"
   ],
   "id": "e270debf448b9dcb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Solution c)\n",
    "c_buses = n_NT_2030h.buses.query(\"country=='IE'\").index\n",
    "c_gen = n_NT_2030h.generators.query(\"carrier=='onwind' and bus in @c_buses\").index\n",
    "c_cf = n_NT_2030h.generators_t.p_max_pu[c_gen]\n",
    "c_cf.mean()"
   ],
   "id": "6bbd2060502b93e9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Task 4: Verify onshore wind trajectories",
   "id": "16da7acdc3d02ff4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Solution\n",
    "(\n",
    "    pd.read_csv(\"resources/tyndp/DE/tyndp_trajectories.csv\", index_col=0)\n",
    "    .query(\"bus=='DE00' and carrier == 'onwind'\")\n",
    "    .set_index(\"pyear\")\n",
    "    .sort_index()[[\"p_nom_min\", \"p_nom_max\"]]\n",
    "    .div(1e3)  # in GW\n",
    ")"
   ],
   "id": "957e588de53814a1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "trj_onwind_de = (\n",
    "    n_DE_2040.generators.query(\"carrier == 'onwind' and bus == 'DE00'\")\n",
    "    .sort_index()[[\"p_nom_opt\", \"p_nom_min\", \"p_nom_max\"]]\n",
    "    .div(1e3)  # in GW\n",
    ")\n",
    "trj_onwind_de"
   ],
   "id": "d3cb84746dd828f7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "(\n",
    "    trj_onwind_de.loc[\"DE00 0 onwind-2040\", [\"p_nom_min\", \"p_nom_max\"]]\n",
    "    + trj_onwind_de.loc[\"DE00 0 onwind-2030\", \"p_nom_opt\"]\n",
    ")"
   ],
   "id": "24400bb162355b18",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Task 5: Extract existing offshore capacities",
   "id": "31761768a9ab0761"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Solution\n",
    "(\n",
    "    s_NT_2030.optimal_capacity(\n",
    "        bus_carrier=[\"AC\", \"AC_OH\", \"H2_OH\"],\n",
    "        comps=\"Generator\",\n",
    "        groupby=[\"bus\", \"carrier\"],\n",
    "    )\n",
    "    .to_frame(\"p_nom_opt\")\n",
    "    .query(\"bus.str.contains('BE') and carrier.str.startswith('offwind')\")\n",
    ")"
   ],
   "id": "9a5dce24354d8ced",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Task 6: Investigate H2 import corridors",
   "id": "d351611432815884"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Solution a)\n",
    "(\n",
    "    n_NT_2030.links.filter(like=\"H2 import\", axis=0).query(\"bus1.str.contains('BE')\")[\n",
    "        [\"bus0\", \"bus1\", \"carrier\", \"p_nom\"]\n",
    "    ]\n",
    ")"
   ],
   "id": "8c29358de2b88664",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Solution b)\n",
    "(\n",
    "    n_DE_2040.links.filter(like=\"H2 import\", axis=0).query(\"bus1.str.contains('BE')\")[\n",
    "        [\"bus0\", \"bus1\", \"carrier\", \"p_nom\"]\n",
    "    ]\n",
    ")"
   ],
   "id": "6e710d55bd4ca2f5",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "language": "python",
   "name": ""
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
